# 神经网络的梯度下降法推导


$m$个样本，每个样本$n$个参数


$$
\begin{array}{l}
	&z^{[1](1)}=W^{[1]}x^{(1)}+b^{[1]}	\\
	&z^{[1](2)}=W^{[1]}x^{(2)}+b^{[1]}	\\
	&\vdots	\\
	&z^{[1](m)}=W^{[1]}x^{(m)}+b^{[1]}	\\
\end{array}
$$

![Image](https://raw.githubusercontent.com/simoonp/picture/main/DeepLearning/net1.svg)

忽略$b^{[1]}$，$W^{[1]}$是一个行向量，$x^{[1]}\ldots x^{[m]}$是$m$个$n \times 1$列向量，$W^{[1]}$为$p\times n$矩阵($p$的大小取决于该层网络中计算单元(神经元)的数量)

$$
\begin{aligned}
	{W^{[1]}}_{p \times n} x_{n \times m} 
	&= \begin{bmatrix}
		\cdots	\\
		\cdots	\\
		\vdots	\\
		\cdots
	\end{bmatrix}	
	\begin{bmatrix}
		x^{(1)}_{1}	&\cdots	&x^{(m)}_{1}	\\
		\vdots	&\ddots	&\vdots	\\
		x^{(1)}_{n}	&\cdots	&x^{(m)}_{n}
	\end{bmatrix}	\\
	&=\begin{bmatrix}
		\sum{(W^{[1]}_{1,1}x^{(1)}_{1}+W^{[1]}_{1,2}x^{(1)}_{2} \cdots W^{[1]}_{n}x^{(1)}_{1,n})}  &\cdots  &\sum^{n}_{i=1}{W^{[1]}_{1,i}x^{(m)}_{i}}	\\
		\vdots	&\cdots	&\vdots	\\
		\sum^{n}_{i=1}{W^{[1]}_{j,i}x^{(1)}_{i}}	&\cdots &\sum^{n}_{i=1}{W^{[1]}_{j,i}x^{(m)}_{i}}	\\
		\vdots	&\ddots	&\vdots	\\
		\sum^{n}_{i=1}{W^{[1]}_{p,i}x^{(1)}_{i}}	&\cdots &\sum^{n}_{i=1}{W^{[1]}_{p,i}x^{(m)}_{i}}
	\end{bmatrix}	\\
	&=\begin{bmatrix}
		\vdots	&\vdots	&\vdots	\\
		W^{[1]}x^{(1)}	&\cdots	&W^{[1]}x^{(m)}	\\
		\vdots	&\vdots	&\vdots	
	\end{bmatrix}	\\
	&=\begin{bmatrix}
		\vdots	&\vdots	&\vdots	\\
		z^{[1](1)} &\cdots &z^{[1](m)}	\\
		\vdots	&\vdots	&\vdots	
	\end{bmatrix}	\\
	&=Z^{[1]}
\end{aligned}
$$

正向传播：
$$
\begin{aligned}
	&(1)z^{[1]} = W^{[1]}x + b^{[1]}	\\
	&(2)a^{[1]} = \sigma(z^{[1]})	\\
	&(3)z^{[2]} = W^{[2]}a^{[1]} + b^{[2]}	\\
	&(4)a^{[2]}=g^{[2]}(z^{[2]})=\sigma(z^{[2]})
\end{aligned}
$$
$$
\begin{aligned}
	&\text{注释：}	\\
	&\hspace{ 30pt }  \hat{y} = a=\sigma(z)	\\
	&\hspace{ 30pt }  \sigma(z)=\frac{1}{1+e^{-z}}	\\
	&\hspace{ 30pt } L(a,y) = -(y\log{a})+(1-y)\log{(1-a)}	\\
	&\hspace{ 30pt } \frac{\mathrm{d}L(a,y)}{\mathrm{d}z} 
		= \frac{\mathrm{d}L(a,y)}{\mathrm{d}a}\frac{\mathrm{d}a}{\mathrm{d}z}
		=(-\frac{y}{a}+\frac{(1-y)}{1-a})(a(1-a))=a-y	\\
	&\hspace{ 30pt }  \text{用}\mathrm{d}z \text{简化表示}\frac{\mathrm{d}L(a,y)}{\mathrm{d}z}	\\
	&\frac{\mathrm{d}L(a^{[2]},y)}{\mathrm{d}z^{[2]}} \Rightarrow \mathrm{d}z^{[2]} = a^{[2]}-y	\\
	&\frac{\mathrm{d}L(a^{[2]},y)}{\mathrm{d}W^{[2]}} \Rightarrow \mathrm{d}W^{[2]}=(\frac{\mathrm{d}L(a^{[2]},y)}{\mathrm{d}z^{[2]}})\mathrm{d}z^{[2]} (\frac{\mathrm{d}z^{[2]}}{\mathrm{d}W^{[2]}})a^{[1]T} \hspace{ 10pt }\text{注:}\mathrm{d}z^{[2]}\text{是列向量，}a^{[1]}\text{也是列向量}
	\\
	&(\frac{\mathrm{d}L(A^{[2]},Y)}{\mathrm{d}z^{[2]}})	\Rightarrow \mathrm{d}z^{[2]} = A^{[2]}-Y	\\
	&\frac{\mathrm{d}L(A^{[2]},Y)}{\mathrm{d}W^{[2]}} \Rightarrow \mathrm{d}W^{[2]}=


	
\end{aligned}
$$


$$
\begin{aligned}
	&m\text{个样本，}每个样本n\text{个参数}
	&
\end{aligned}
$$